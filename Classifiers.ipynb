{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ze/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.datasets as sk_data\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "import sklearn.cluster as sk_cluster\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from smart_open import smart_open \n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the \"yelp_academic_dataset_business.json\" dataset keep businesses from the city of Toronto with the categories \"Beauty & Spas\", \"Shopping\" and \"Bars\", which they have at least 10 reviews.\n",
    "\n",
    "For each business on the list get all the reviews for the business from the \"yelp_academic_dataset_review.json\" dataset and merge them in a great text for business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = []\n",
    "\n",
    "with open(\"yelp_academic_dataset_business.json\", encoding = \"utf8\", errors = \"ignore\") as f:\n",
    "    for line in f:\n",
    "        get_line = json.loads(line)\n",
    "        business_id = get_line[\"business_id\"]\n",
    "        cat = get_line[\"categories\"]\n",
    "        # split categories from text to array\n",
    "        if cat is not None:\n",
    "            category = cat.split(\", \")\n",
    "        city = get_line[\"city\"]\n",
    "        count = get_line[\"review_count\"]\n",
    "        beauty = \"Beauty & Spas\"\n",
    "        shopping = \"Shopping\"\n",
    "        bars = \"Bars\"\n",
    "        if city == \"Toronto\" and count>=10:                    \n",
    "            if beauty in category:\n",
    "                # if Beauty & Spas\n",
    "                business.append((business_id,beauty))\n",
    "            elif shopping in category:\n",
    "                # if Shopping\n",
    "                business.append((business_id,shopping))\n",
    "            elif bars in category:\n",
    "                # if Bars\n",
    "                business.append((business_id,bars))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get reviews where business in Toronto\n",
    "only_bs = np.array(business)\n",
    "check_for_business = list(only_bs[:,0])\n",
    "\n",
    "reviews = []\n",
    "\n",
    "with open(\"yelp_academic_dataset_review.json\", encoding = \"utf8\", errors = \"ignore\") as f: \n",
    "    for line in f:\n",
    "        get_line = json.loads(line)\n",
    "        # get business id\n",
    "        business_id = get_line[\"business_id\"]\n",
    "        # get text of business\n",
    "        text = get_line[\"text\"]\n",
    "\n",
    "        if business_id in check_for_business:\n",
    "            reviews.append((business_id,text))\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing stemming\n",
    "\n",
    "# for each business keep all the reviews given together in a text\n",
    "reviews_per_business = []\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for b in range(len(business)):\n",
    "\n",
    "    # empty text for each business\n",
    "    text_per_business=\"\"\n",
    "    for r in range(len(reviews)):\n",
    "        if business[b][0]==reviews[r][0]:\n",
    "            \n",
    "            # remove punctuation\n",
    "            text = re.sub(\"[^a-zA-Z]\",\" \",reviews[r][1])\n",
    "            # remove tags\n",
    "            text = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "            # remove special characters and digits\n",
    "            text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "            # lower cases only\n",
    "            text = text.lower()\n",
    "            text = word_tokenize(text)\n",
    "            stem = [ps.stem(w) for w in text]\n",
    "            # do the stemming\n",
    "            for w in stem:\n",
    "                text_per_business+= \" \" + w\n",
    "            \n",
    "    reviews_per_business.append((business[b][0],business[b][1],text_per_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicPsia8Wj-DNRkmLbD_xg</td>\n",
       "      <td>Bars</td>\n",
       "      <td>consist good as the keg tend to be highlight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xVXyrTWbG8U3szze-aA7eg</td>\n",
       "      <td>Bars</td>\n",
       "      <td>i would give zero star i came here with a gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e-tRKAC-q40SqQfAOwYa-A</td>\n",
       "      <td>Beauty &amp; Spas</td>\n",
       "      <td>a bliss experi i highli recommend thi place i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9keC4mWuXdl2mYFHZXudQ</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>if you re a boy and you want to wear some hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PFS9kf3U-ZCvpqay3AaNnQ</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>as a countri girl i often find myself miss th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>Cesnh6fIsAUO8D4jfGhOIw</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>good taco in the downtown core are hard to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>lkq6i2x3vUsR7ZNrIFqoIw</td>\n",
       "      <td>Bars</td>\n",
       "      <td>thi use to be my favourit place it wa alway p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>wjqOdj0XJUDOOtU9LjRlWQ</td>\n",
       "      <td>Bars</td>\n",
       "      <td>veri welcom place great setup and super frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>AqpB2IoLkUupDCuH-hmVdg</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>i can t beleiv i am say thi but i left thi sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0hudPyuCBlKg79OwKBw-eQ</td>\n",
       "      <td>Bars</td>\n",
       "      <td>we had pizza and fish chip the pizza wa not d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id       category  \\\n",
       "0     cicPsia8Wj-DNRkmLbD_xg           Bars   \n",
       "1     xVXyrTWbG8U3szze-aA7eg           Bars   \n",
       "2     e-tRKAC-q40SqQfAOwYa-A  Beauty & Spas   \n",
       "3     C9keC4mWuXdl2mYFHZXudQ       Shopping   \n",
       "4     PFS9kf3U-ZCvpqay3AaNnQ       Shopping   \n",
       "...                      ...            ...   \n",
       "2986  Cesnh6fIsAUO8D4jfGhOIw       Shopping   \n",
       "2987  lkq6i2x3vUsR7ZNrIFqoIw           Bars   \n",
       "2988  wjqOdj0XJUDOOtU9LjRlWQ           Bars   \n",
       "2989  AqpB2IoLkUupDCuH-hmVdg       Shopping   \n",
       "2990  0hudPyuCBlKg79OwKBw-eQ           Bars   \n",
       "\n",
       "                                                   text  \n",
       "0      consist good as the keg tend to be highlight ...  \n",
       "1      i would give zero star i came here with a gro...  \n",
       "2      a bliss experi i highli recommend thi place i...  \n",
       "3      if you re a boy and you want to wear some hot...  \n",
       "4      as a countri girl i often find myself miss th...  \n",
       "...                                                 ...  \n",
       "2986   good taco in the downtown core are hard to co...  \n",
       "2987   thi use to be my favourit place it wa alway p...  \n",
       "2988   veri welcom place great setup and super frien...  \n",
       "2989   i can t beleiv i am say thi but i left thi sh...  \n",
       "2990   we had pizza and fish chip the pizza wa not d...  \n",
       "\n",
       "[2991 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array to dataframe\n",
    "df = pd.DataFrame(data=reviews_per_business,columns=[\"business_id\",\"category\",\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text per business\n",
    "corpus = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicPsia8Wj-DNRkmLbD_xg</td>\n",
       "      <td>Bars</td>\n",
       "      <td>consist good as the keg tend to be highlight ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xVXyrTWbG8U3szze-aA7eg</td>\n",
       "      <td>Bars</td>\n",
       "      <td>i would give zero star i came here with a gro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e-tRKAC-q40SqQfAOwYa-A</td>\n",
       "      <td>Beauty &amp; Spas</td>\n",
       "      <td>a bliss experi i highli recommend thi place i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9keC4mWuXdl2mYFHZXudQ</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>if you re a boy and you want to wear some hot...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PFS9kf3U-ZCvpqay3AaNnQ</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>as a countri girl i often find myself miss th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>Cesnh6fIsAUO8D4jfGhOIw</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>good taco in the downtown core are hard to co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>lkq6i2x3vUsR7ZNrIFqoIw</td>\n",
       "      <td>Bars</td>\n",
       "      <td>thi use to be my favourit place it wa alway p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>wjqOdj0XJUDOOtU9LjRlWQ</td>\n",
       "      <td>Bars</td>\n",
       "      <td>veri welcom place great setup and super frien...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>AqpB2IoLkUupDCuH-hmVdg</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>i can t beleiv i am say thi but i left thi sh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0hudPyuCBlKg79OwKBw-eQ</td>\n",
       "      <td>Bars</td>\n",
       "      <td>we had pizza and fish chip the pizza wa not d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id       category  \\\n",
       "0     cicPsia8Wj-DNRkmLbD_xg           Bars   \n",
       "1     xVXyrTWbG8U3szze-aA7eg           Bars   \n",
       "2     e-tRKAC-q40SqQfAOwYa-A  Beauty & Spas   \n",
       "3     C9keC4mWuXdl2mYFHZXudQ       Shopping   \n",
       "4     PFS9kf3U-ZCvpqay3AaNnQ       Shopping   \n",
       "...                      ...            ...   \n",
       "2986  Cesnh6fIsAUO8D4jfGhOIw       Shopping   \n",
       "2987  lkq6i2x3vUsR7ZNrIFqoIw           Bars   \n",
       "2988  wjqOdj0XJUDOOtU9LjRlWQ           Bars   \n",
       "2989  AqpB2IoLkUupDCuH-hmVdg       Shopping   \n",
       "2990  0hudPyuCBlKg79OwKBw-eQ           Bars   \n",
       "\n",
       "                                                   text  label  \n",
       "0      consist good as the keg tend to be highlight ...      0  \n",
       "1      i would give zero star i came here with a gro...      0  \n",
       "2      a bliss experi i highli recommend thi place i...      1  \n",
       "3      if you re a boy and you want to wear some hot...      2  \n",
       "4      as a countri girl i often find myself miss th...      2  \n",
       "...                                                 ...    ...  \n",
       "2986   good taco in the downtown core are hard to co...      2  \n",
       "2987   thi use to be my favourit place it wa alway p...      0  \n",
       "2988   veri welcom place great setup and super frien...      0  \n",
       "2989   i can t beleiv i am say thi but i left thi sh...      2  \n",
       "2990   we had pizza and fish chip the pizza wa not d...      0  \n",
       "\n",
       "[2991 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set 0,1,2 labels for each category\n",
    "labelEnc = LabelEncoder()\n",
    "categories = labelEnc.fit_transform(df[\"category\"])\n",
    "df[\"label\"] = categories\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target labels\n",
    "target_labels = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get TF-IDF and experiment with Logistic Regression, SVM and K-NN. Using 5-fold cross validation for the evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "2986    2\n",
       "2987    0\n",
       "2988    0\n",
       "2989    2\n",
       "2990    0\n",
       "Name: label, Length: 2991, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get true values\n",
    "y = df.label\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        consist good as the keg tend to be highlight ...\n",
       "1        i would give zero star i came here with a gro...\n",
       "2        a bliss experi i highli recommend thi place i...\n",
       "3        if you re a boy and you want to wear some hot...\n",
       "4        as a countri girl i often find myself miss th...\n",
       "                              ...                        \n",
       "2986     good taco in the downtown core are hard to co...\n",
       "2987     thi use to be my favourit place it wa alway p...\n",
       "2988     veri welcom place great setup and super frien...\n",
       "2989     i can t beleiv i am say thi but i left thi sh...\n",
       "2990     we had pizza and fish chip the pizza wa not d...\n",
       "Name: text, Length: 2991, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get text\n",
    "X = df.text\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the train_test_split method\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing TfidfVectorizer\n",
    "\n",
    "# The lower the value of a word, the less unique it is to any particular document.\n",
    "\n",
    "# min_df = 20, ignore terms that appeared in less than 20 documents \n",
    "# max_df = 0.7, ignore terms that appear in 70% of the documents\n",
    "\n",
    "vectorizer = sk_text.TfidfVectorizer(stop_words = 'english',min_df=20,max_df=0.70,max_features = 1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5788770053475936\n",
      "\n",
      "Confusion matrix\n",
      "[[146   2 164]\n",
      " [  0  91 121]\n",
      " [ 11  17 196]]\n",
      "\n",
      "Average Precision Score:\t 0.7443829583514178\n",
      "\n",
      "Average Recall Score:\t 0.5788770053475936\n",
      "\n",
      "Average F1 Score:\t 0.5864011239486261\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "lr_clf = linear_model.LogisticRegression(solver='lbfgs')\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = lr_clf.predict(X_test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion matrix\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# average precision score\n",
    "average_precision_score = metrics.precision_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Precision Score:\\t\",average_precision_score)\n",
    "\n",
    "# average recall score\n",
    "average_recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Recall Score:\\t\",average_recall_score)\n",
    "\n",
    "# average f1 score\n",
    "average_f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage F1 Score:\\t\",average_f1_score)\n",
    "\n",
    "# keep a dataframe for all\n",
    "data_total = []\n",
    "\n",
    "data_total.append((\"Logistic Regression\",accuracy,average_precision_score,average_recall_score,average_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision weighted mean:\t 0.9644548115688611 \n",
      "Test recall weighted mean:\t 0.9638899936366527 \n",
      "Test f1 score weighted mean:\t 0.9638018390607941\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "scores = model_selection.cross_validate(lr_clf, X_train_tfidf,y_train,\n",
    "                                    scoring=[\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"],cv=5)\n",
    "\n",
    "print (\"Test precision weighted mean:\\t\",scores['test_precision_weighted'].mean(),\n",
    "       \"\\nTest recall weighted mean:\\t\",scores['test_recall_weighted'].mean(),\n",
    "      \"\\nTest f1 score weighted mean:\\t\",scores['test_f1_weighted'].mean())\n",
    "\n",
    "data_total_k_fold = []\n",
    "data_total_k_fold.append((\"Logistic Regression\",scores['test_precision_weighted'].mean(),\n",
    "                         scores['test_recall_weighted'].mean(),scores['test_f1_weighted'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5200534759358288\n",
      "\n",
      "Confusion matrix\n",
      "[[115   0 197]\n",
      " [  0  70 142]\n",
      " [ 17   3 204]]\n",
      "\n",
      "Average Precision Score:\t 0.7476745309941913\n",
      "\n",
      "Average Recall Score:\t 0.5200534759358288\n",
      "\n",
      "Average F1 Score:\t 0.5145950834674139\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(X_train_tfidf,y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion matrix\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# average precision score\n",
    "average_precision_score = metrics.precision_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Precision Score:\\t\",average_precision_score)\n",
    "\n",
    "# average recall score\n",
    "average_recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Recall Score:\\t\",average_recall_score)\n",
    "\n",
    "# average f1 score\n",
    "average_f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage F1 Score:\\t\",average_f1_score)\n",
    "\n",
    "data_total.append((\"SVM Classification\",accuracy,average_precision_score,average_recall_score,average_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision weighted mean:\t 0.963029843818167 \n",
      "Test recall weighted mean:\t 0.9625546850143175 \n",
      "Test f1 score weighted mean:\t 0.9624272735251171\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = model_selection.cross_validate(svm_clf, X_train_tfidf,y_train,\n",
    "                                    scoring=[\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"],cv=5)\n",
    "\n",
    "print (\"Test precision weighted mean:\\t\",scores['test_precision_weighted'].mean(),\n",
    "       \"\\nTest recall weighted mean:\\t\",scores['test_recall_weighted'].mean(),\n",
    "      \"\\nTest f1 score weighted mean:\\t\",scores['test_f1_weighted'].mean())\n",
    "\n",
    "data_total_k_fold.append((\"SVM Classification\",scores['test_precision_weighted'].mean(),\n",
    "                         scores['test_recall_weighted'].mean(),scores['test_f1_weighted'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6537433155080213\n",
      "\n",
      "Confusion matrix\n",
      "[[273   7  32]\n",
      " [ 32 119  61]\n",
      " [ 89  38  97]]\n",
      "\n",
      "Average Precision Score:\t 0.6475533477891394\n",
      "\n",
      "Average Recall Score:\t 0.6537433155080213\n",
      "\n",
      "Average F1 Score:\t 0.6423121091432232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_tfidf,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_tfidf)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion matrix\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# average precision score\n",
    "average_precision_score = metrics.precision_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Precision Score:\\t\",average_precision_score)\n",
    "\n",
    "# average recall score\n",
    "average_recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Recall Score:\\t\",average_recall_score)\n",
    "\n",
    "# average f1 score\n",
    "average_f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage F1 Score:\\t\",average_f1_score)\n",
    "\n",
    "data_total.append((\"k-NN Classification\",accuracy,average_precision_score,average_recall_score,average_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision weighted mean:\t 0.948969703640224 \n",
      "Test recall weighted mean:\t 0.9487352847597836 \n",
      "Test f1 score weighted mean:\t 0.9482673034553715\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = model_selection.cross_validate(knn, X_train_tfidf,y_train,\n",
    "                                    scoring=[\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"],cv=5)\n",
    "\n",
    "print (\"Test precision weighted mean:\\t\",scores['test_precision_weighted'].mean(),\n",
    "       \"\\nTest recall weighted mean:\\t\",scores['test_recall_weighted'].mean(),\n",
    "      \"\\nTest f1 score weighted mean:\\t\",scores['test_f1_weighted'].mean())\n",
    "\n",
    "data_total_k_fold.append((\"k-NN Classification\",scores['test_precision_weighted'].mean(),\n",
    "                         scores['test_recall_weighted'].mean(),scores['test_f1_weighted'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificator's Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificator</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Average Precision Score</th>\n",
       "      <th>Average Recall Score</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.578877</td>\n",
       "      <td>0.744383</td>\n",
       "      <td>0.578877</td>\n",
       "      <td>0.586401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>0.520053</td>\n",
       "      <td>0.747675</td>\n",
       "      <td>0.520053</td>\n",
       "      <td>0.514595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN Classification</td>\n",
       "      <td>0.653743</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>0.653743</td>\n",
       "      <td>0.642312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classificator  Accuracy  Average Precision Score  \\\n",
       "0  Logistic Regression  0.578877                 0.744383   \n",
       "1   SVM Classification  0.520053                 0.747675   \n",
       "2  k-NN Classification  0.653743                 0.647553   \n",
       "\n",
       "   Average Recall Score  Average F1 Score  \n",
       "0              0.578877          0.586401  \n",
       "1              0.520053          0.514595  \n",
       "2              0.653743          0.642312  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total = pd.DataFrame(data=data_total,columns=[\"Classificator\",\"Accuracy\",\"Average Precision Score\",\n",
    "                                                   \"Average Recall Score\",\"Average F1 Score\"])\n",
    "data_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented a better stemming (in addition with clustering-previous exercise) for our data so for the results, the overall accuracy is high -Logistic Regression and SVM ~0.74. Recall, is low and only k-NN seems to be better for applying classification, and f1 score is low as expected (precision-recall are low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As comparison with clustering, clustering was better, only Agglomerative - Single precision and recall was 0.4203 and 0.4215 respectively. K-means, Agglomerative - Complete, Agglomerative - Average, Agglomerative - Ward had values close to 1 (>=0.81)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-fold cross validation</th>\n",
       "      <th>Test Precicion Weighted</th>\n",
       "      <th>Test Recall Weighted</th>\n",
       "      <th>Test F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.964455</td>\n",
       "      <td>0.963890</td>\n",
       "      <td>0.963802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>0.963030</td>\n",
       "      <td>0.962555</td>\n",
       "      <td>0.962427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN Classification</td>\n",
       "      <td>0.948970</td>\n",
       "      <td>0.948735</td>\n",
       "      <td>0.948267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  5-fold cross validation  Test Precicion Weighted  Test Recall Weighted  \\\n",
       "0     Logistic Regression                 0.964455              0.963890   \n",
       "1      SVM Classification                 0.963030              0.962555   \n",
       "2     k-NN Classification                 0.948970              0.948735   \n",
       "\n",
       "   Test F1 Weighted  \n",
       "0          0.963802  \n",
       "1          0.962427  \n",
       "2          0.948267  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total_k_fold = pd.DataFrame(data=data_total_k_fold,\n",
    "                                 columns=[\"5-fold cross validation\",\"Test Precicion Weighted\",\n",
    "                                          \"Test Recall Weighted\",\"Test F1 Weighted\"])\n",
    "\n",
    "data_total_k_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 5-fold cross validation, all precision, recall and f1 score are high enough, it is very good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same implementation as before but now extracting features using Word Emdendings of Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ze/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string as string\n",
    "\n",
    "X_train_nltk = []\n",
    "y_train_nltk = []\n",
    "for x,y in zip(X_train,y_train):\n",
    "    wt = word_tokenize(x.lower())\n",
    "    doc = [w for w in wt if w not in string.punctuation]\n",
    "    if len(doc) == 0: continue\n",
    "    X_train_nltk.append(doc)\n",
    "    y_train_nltk.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ze/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "english_stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nltk = []\n",
    "y_test_nltk = []\n",
    "\n",
    "for x,y in zip(X_test,y_test):\n",
    "    wt = word_tokenize(x.lower())\n",
    "    doc = [w for w in wt if (w not in english_stop_words) and (w not in string.punctuation)]\n",
    "    if len(doc) == 0: continue    \n",
    "    X_test_nltk.append(doc)\n",
    "    y_test_nltk.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-5d85d78b726a>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if w in g_model.wv:\n"
     ]
    }
   ],
   "source": [
    "X_train_gmodel = []\n",
    "for x in X_train_nltk:\n",
    "    vx = np.zeros(300)\n",
    "    length = 0\n",
    "    for w in x: \n",
    "        if w in g_model.wv:\n",
    "            length += 1\n",
    "            vx += g_model[w]\n",
    "    if length != 0: vx /= length\n",
    "    X_train_gmodel.append(vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-e37839b034e5>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if (w not in g_model.wv): continue\n",
      "<ipython-input-30-e37839b034e5>:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vx += g_model.wv[w]\n"
     ]
    }
   ],
   "source": [
    "X_test_gmodel = []\n",
    "for x in X_test_nltk:\n",
    "    vx = np.zeros(300)\n",
    "    length = 0\n",
    "    for w in x: \n",
    "        if (w not in g_model.wv): continue\n",
    "        length += 1\n",
    "        vx += g_model.wv[w]\n",
    "    if length != 0: vx /= length\n",
    "    X_test_gmodel.append(vx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9264705882352942\n",
      "\n",
      "Confusion matrix\n",
      "[[312   0   0]\n",
      " [  8 189  15]\n",
      " [ 32   0 192]]\n",
      "\n",
      "Average Precision Score:\t 0.9309004953041223\n",
      "\n",
      "Average Recall Score:\t 0.9264705882352942\n",
      "\n",
      "Average F1 Score:\t 0.9259602996343181\n"
     ]
    }
   ],
   "source": [
    "lr_clf = linear_model.LogisticRegression(solver='lbfgs')\n",
    "lr_clf.fit(X_train_gmodel, y_train_nltk)\n",
    "\n",
    "y_pred = lr_clf.predict(X_test_gmodel)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion matrix\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# average precision score\n",
    "average_precision_score = metrics.precision_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Precision Score:\\t\",average_precision_score)\n",
    "\n",
    "# average recall score\n",
    "average_recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Recall Score:\\t\",average_recall_score)\n",
    "\n",
    "# average f1 score\n",
    "average_f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage F1 Score:\\t\",average_f1_score)\n",
    "\n",
    "# keep a dataframe for all\n",
    "data_total_nltk = []\n",
    "\n",
    "data_total_nltk.append((\"Logistic Regression\",accuracy,average_precision_score,average_recall_score,average_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision weighted mean:\t 0.9644548115688611 \n",
      "Test recall weighted mean:\t 0.9638899936366527 \n",
      "Test f1 score weighted mean:\t 0.9638018390607941\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = model_selection.cross_validate(lr_clf, X_train_tfidf,y_train,\n",
    "                                    scoring=[\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"],cv=5)\n",
    "\n",
    "print (\"Test precision weighted mean:\\t\",scores['test_precision_weighted'].mean(),\n",
    "       \"\\nTest recall weighted mean:\\t\",scores['test_recall_weighted'].mean(),\n",
    "      \"\\nTest f1 score weighted mean:\\t\",scores['test_f1_weighted'].mean())\n",
    "\n",
    "data_total_k_fold_nltk = []\n",
    "data_total_k_fold_nltk.append((\"Logistic Regression\",scores['test_precision_weighted'].mean(),\n",
    "                         scores['test_recall_weighted'].mean(),scores['test_f1_weighted'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9491978609625669\n",
      "\n",
      "Confusion matrix\n",
      "[[312   0   0]\n",
      " [  1 197  14]\n",
      " [ 23   0 201]]\n",
      "\n",
      "Average Precision Score:\t 0.9507062021425907\n",
      "\n",
      "Average Recall Score:\t 0.9491978609625669\n",
      "\n",
      "Average F1 Score:\t 0.9489172623651538\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(X_train_gmodel,y_train_nltk)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test_gmodel)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion matrix\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# average precision score\n",
    "average_precision_score = metrics.precision_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Precision Score:\\t\",average_precision_score)\n",
    "\n",
    "# average recall score\n",
    "average_recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Recall Score:\\t\",average_recall_score)\n",
    "\n",
    "# average f1 score\n",
    "average_f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage F1 Score:\\t\",average_f1_score)\n",
    "\n",
    "data_total_nltk.append((\"SVM Classification\",accuracy,average_precision_score,average_recall_score,average_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision weighted mean:\t 0.963029843818167 \n",
      "Test recall weighted mean:\t 0.9625546850143175 \n",
      "Test f1 score weighted mean:\t 0.9624272735251171\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = model_selection.cross_validate(svm_clf, X_train_tfidf,y_train,\n",
    "                                    scoring=[\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"],cv=5)\n",
    "\n",
    "print (\"Test precision weighted mean:\\t\",scores['test_precision_weighted'].mean(),\n",
    "       \"\\nTest recall weighted mean:\\t\",scores['test_recall_weighted'].mean(),\n",
    "      \"\\nTest f1 score weighted mean:\\t\",scores['test_f1_weighted'].mean())\n",
    "\n",
    "data_total_k_fold_nltk.append((\"SVM Classification\",scores['test_precision_weighted'].mean(),\n",
    "                         scores['test_recall_weighted'].mean(),scores['test_f1_weighted'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9398395721925134\n",
      "\n",
      "Confusion matrix\n",
      "[[312   0   0]\n",
      " [  0 196  16]\n",
      " [ 28   1 195]]\n",
      "\n",
      "Average Precision Score:\t 0.9415026179551339\n",
      "\n",
      "Average Recall Score:\t 0.9398395721925134\n",
      "\n",
      "Average F1 Score:\t 0.939327643394975\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_gmodel,y_train_nltk)\n",
    "\n",
    "y_pred = knn.predict(X_test_gmodel)\n",
    "\n",
    "# accuracy\n",
    "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy:\",accuracy)\n",
    "\n",
    "# confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(\"\\nConfusion matrix\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# average precision score\n",
    "average_precision_score = metrics.precision_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Precision Score:\\t\",average_precision_score)\n",
    "\n",
    "# average recall score\n",
    "average_recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage Recall Score:\\t\",average_recall_score)\n",
    "\n",
    "# average f1 score\n",
    "average_f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "print(\"\\nAverage F1 Score:\\t\",average_f1_score)\n",
    "\n",
    "data_total_nltk.append((\"k-NN Classification\",accuracy,average_precision_score,average_recall_score,average_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision weighted mean:\t 0.948969703640224 \n",
      "Test recall weighted mean:\t 0.9487352847597836 \n",
      "Test f1 score weighted mean:\t 0.9482673034553715\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "scores = model_selection.cross_validate(knn, X_train_tfidf,y_train,\n",
    "                                    scoring=[\"precision_weighted\",\"recall_weighted\",\"f1_weighted\"],cv=5)\n",
    "\n",
    "print (\"Test precision weighted mean:\\t\",scores['test_precision_weighted'].mean(),\n",
    "       \"\\nTest recall weighted mean:\\t\",scores['test_recall_weighted'].mean(),\n",
    "      \"\\nTest f1 score weighted mean:\\t\",scores['test_f1_weighted'].mean())\n",
    "\n",
    "data_total_k_fold_nltk.append((\"k-NN Classification\",scores['test_precision_weighted'].mean(),\n",
    "                         scores['test_recall_weighted'].mean(),scores['test_f1_weighted'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificator's Results - Word Embeddigs Google (WEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificator</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Average Precision Score</th>\n",
       "      <th>Average Recall Score</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.930900</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.925960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.950706</td>\n",
       "      <td>0.949198</td>\n",
       "      <td>0.948917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN Classification</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>0.941503</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>0.939328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classificator  Accuracy  Average Precision Score  \\\n",
       "0  Logistic Regression  0.926471                 0.930900   \n",
       "1   SVM Classification  0.949198                 0.950706   \n",
       "2  k-NN Classification  0.939840                 0.941503   \n",
       "\n",
       "   Average Recall Score  Average F1 Score  \n",
       "0              0.926471          0.925960  \n",
       "1              0.949198          0.948917  \n",
       "2              0.939840          0.939328  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total_nltk = pd.DataFrame(data=data_total_nltk,columns=[\"Classificator\",\"Accuracy\",\"Average Precision Score\",\n",
    "                                                   \"Average Recall Score\",\"Average F1 Score\"])\n",
    "data_total_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold cross validation - Word Embeddigs Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-fold cross validation</th>\n",
       "      <th>Test Precicion Weighted</th>\n",
       "      <th>Test Recall Weighted</th>\n",
       "      <th>Test F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.964455</td>\n",
       "      <td>0.963890</td>\n",
       "      <td>0.963802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>0.963030</td>\n",
       "      <td>0.962555</td>\n",
       "      <td>0.962427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN Classification</td>\n",
       "      <td>0.948970</td>\n",
       "      <td>0.948735</td>\n",
       "      <td>0.948267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  5-fold cross validation  Test Precicion Weighted  Test Recall Weighted  \\\n",
       "0     Logistic Regression                 0.964455              0.963890   \n",
       "1      SVM Classification                 0.963030              0.962555   \n",
       "2     k-NN Classification                 0.948970              0.948735   \n",
       "\n",
       "   Test F1 Weighted  \n",
       "0          0.963802  \n",
       "1          0.962427  \n",
       "2          0.948267  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total_k_fold_nltk = pd.DataFrame(data=data_total_k_fold_nltk,\n",
    "                                 columns=[\"5-fold cross validation\",\"Test Precicion Weighted\",\n",
    "                                          \"Test Recall Weighted\",\"Test F1 Weighted\"])\n",
    "\n",
    "data_total_k_fold_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificator's Results - Without WEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificator</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Average Precision Score</th>\n",
       "      <th>Average Recall Score</th>\n",
       "      <th>Average F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.578877</td>\n",
       "      <td>0.744383</td>\n",
       "      <td>0.578877</td>\n",
       "      <td>0.586401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>0.520053</td>\n",
       "      <td>0.747675</td>\n",
       "      <td>0.520053</td>\n",
       "      <td>0.514595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN Classification</td>\n",
       "      <td>0.653743</td>\n",
       "      <td>0.647553</td>\n",
       "      <td>0.653743</td>\n",
       "      <td>0.642312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classificator  Accuracy  Average Precision Score  \\\n",
       "0  Logistic Regression  0.578877                 0.744383   \n",
       "1   SVM Classification  0.520053                 0.747675   \n",
       "2  k-NN Classification  0.653743                 0.647553   \n",
       "\n",
       "   Average Recall Score  Average F1 Score  \n",
       "0              0.578877          0.586401  \n",
       "1              0.520053          0.514595  \n",
       "2              0.653743          0.642312  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold cross validation - Without WEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-fold cross validation</th>\n",
       "      <th>Test Precicion Weighted</th>\n",
       "      <th>Test Recall Weighted</th>\n",
       "      <th>Test F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.964455</td>\n",
       "      <td>0.963890</td>\n",
       "      <td>0.963802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>0.963030</td>\n",
       "      <td>0.962555</td>\n",
       "      <td>0.962427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k-NN Classification</td>\n",
       "      <td>0.948970</td>\n",
       "      <td>0.948735</td>\n",
       "      <td>0.948267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  5-fold cross validation  Test Precicion Weighted  Test Recall Weighted  \\\n",
       "0     Logistic Regression                 0.964455              0.963890   \n",
       "1      SVM Classification                 0.963030              0.962555   \n",
       "2     k-NN Classification                 0.948970              0.948735   \n",
       "\n",
       "   Test F1 Weighted  \n",
       "0          0.963802  \n",
       "1          0.962427  \n",
       "2          0.948267  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_total_k_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the results using word embeddings of Google, are better and they have close value to 1, all metrics, accuracy, precicion, recall and f1 score are high enough. \n",
    "With 5-fold cross validation we are getting same results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
